
GSHMC 
implemented on gromacs-4.5.4

Brief description

Introduction:

Generalized Shadow Hybrid Monte Carlo (GSHMC) is a new simulation protocol proposed by E. Akhmatskaya and S. Reich (Journal of Computational Physics, 227 (2008) 4934 – 4954). 

The main advantage of GSHMC is that it is flexible enough to cover a wide range of applications. Contrary to most Monte Carlo methods it is closely linked to kinetics and can provide information on dynamics as well as pure sampling (thermodynamics) which is crucial for many applications. It has a much improved acceptance rate over traditional hybrid Monte Carlo (HMC) at very little additional cost.

GSHMC is a rigorous method, as opposed to many empirical (kinetic-based) sampling methods (such as the Berendsen thermostat, numerical implementations of Brownian and Langevin dynamics, etc.).

Therefore, the GSHMC code can be applied to the simulation of a broad range of physical systems as an alternative to molecular dynamics, Monte Carlo or hybrid Monte Carlo.


Objectives: 
Implementation of the Generalised Shadow Hybrid Monte Carlo (GSHMC) algorithm on the molecular dynamics software GROMACS minimizing modifications to the source code and computational overhead.
Compare the efficiency and accuracy of the modified code with standard GROMACS.
Apply this implementation to the case of  protein folding and metal binding.
Compilation

To compile gromacs you will need the 'cmake' package installed. 

1. Compiling on gauss:

On gauss you will need to compile the FFTW3 libraries from source using the PIC flags. Run the following commands, where '--prefix' indicates the destination directory:

./configure 	CXXFLAGS=-fPIC 	\
		CFLAGS=-fPIC	\
		CPPFLAGS=-fPIC	\
		--prefix=/data1/bescribano/GROMACS/FFTW3/ 
make
make install


To compile gromacs, change to the 'gromacs-4.5.4_GSHMC' directory and run the following commands:

mkdir exec
cd exec
make clean

cmake -D FFTW3_INCLUDE_DIR=/data1/bescribano/GROMACS/FFTW3/include \
      -D FFTW3_LIBRARIES=/data1/bescribano/GROMACS/FFTW3/lib/libfftw3.a \
      -D GMX_THREADS:BOOL=ON \
      -D CMAKE_BUILD_TYPE=Release \
      -D CMAKE_INSTALL_PREFIX=../exec/ \
      -D GMX_DOUBLE=ON \
      ../../gromacs-4.5.4_GSHMC/

make -j 4
make install

NOTES:
use -D GMX_THREADS:BOOL=ON for running in parallel in several cores of the same processor. Change to 'OFF' for serial running on one core.
change /data1/bescribano/gromacs/FFTW3/ for the path where you installed the FFTW3 libraries.
use  -D CMAKE_BUILD_TYPE=Debug  for the debugging version.
use -D GMX_DOUBLE=OFF for simple precision.
the option “-j 4“ is useful for compiling in parallel using 4 processors (when available).


2. Compiling on ARINA:

It is preferable to use the Xeon processors on the guinness server. Connect to guinness using:

ssh -X username@guinness.lgp.ehu.es

Copy the 'gromacs-4.5.4_GSHMC' directory to your $HOME.

For compiling the MPI version, use the following script from the gromacs-4.5.4_GSHMC directory:

#!/bin/bash -x
GROMACS_HOME=$HOME/gromacs-4.5.4_GSHMC

MPI_HOME="/opt/mpi/mpibull2-1.3.9-18.s/"
suff="_d_mpibull_gshmc"

CPPFLAGS="-I/software/fftw-3.2.2/include -I/$MPI_HOME/include" 
MPICC="$MPI_HOME/bin/mpicc"
LDFLAGS="-L/software/fftw-3.2.2/lib -L/usr/lib -L/$MPI_HOME/lib"
LIBS="/software/fftw-3.2.2/lib/libfftw3.so.3 -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lpthread"
CFLAGS=" -O3 "
CXX="icpc"
CC="icc"
F77="ifort"

make clean

cmake -D FFTW3_INCLUDE_DIR=/software/fftw-3.2.2/include \
      -D FFTW3_LIBRARIES=/software/fftw-3.2.2/lib/libfftw3.a \
      -D GMX_THREADS:BOOL=ON \
      -D CMAKE_BUILD_TYPE=Release \
      -D CMAKE_INSTALL_PREFIX=$GROMACS_HOME/exec/ \
      -D GMX_DOUBLE=ON \
      -D CMAKE_CXX_COMPILER=$MPI_HOME/bin/mpicxx \
      -D CMAKE_C_COMPILER=$MPI_HOME/bin/mpicc \
-D GMX_EXTERNAL_LAPACK=ON \
-D GMX_EXTERNAL_BLAS=ON \
-D GMX_GSL=ON \
-D BUILD_SHARED_LIBS=ON \
      -D GMX_MPI=ON \
      -D GMX_DEFAULT_SUFFIX=OFF \
      -D GMX_BINARY_SUFFIX=$suff \
      -D GMX_LIBS_SUFFIX=$suff \
      $GROMACS_HOME

make -j 4

make install
make install-mdrun






Running

Before starting any simulations, you must add the following line to your .bashrc file and restart your terminal:

source $HOME/gromacs-4.5.4_GSHMC/exec/bin/GMXRC

NOTE: on guinness, you might need to use GMXRC.bash instead of GMXRC

For running short tests without waiting the queue, use the following script, where N_tot is the number of processors:

#!/bin/bash -x

MPI_HOME="/opt/mpi/mpibull2-1.3.9-18.s/"
N_tot=8
par_lib="_gshmc"

rundir=`pwd`
GROMACS_HOME=/home/cixesesb/gromacs-4.5.4_GSHMC
bindir=$GROMACS_HOME/exec/bin
GMXLIB=$GROMACS_HOME/share/top

echo "A total number of cores / processes is " $N_tot

suff="_d_mpibull$par_lib"

if [ -f $rundir/index.ndx ] 
then
   $bindir/grompp$suff -f equil_nvt.mdp -c equil_nvt.gro -p neutral.top -po mdout.mdp -o topol.tpr -n index.ndx  
else
   $bindir/grompp$suff -f equil_nvt.mdp -c equil_nvt.gro -p neutral.top -po mdout.mdp -o topol.tpr  
fi

$MPI_HOME/bin/mpirun -np $N_tot $bindir/mdrun$suff -s topol.tpr -o traj.trr -c confout.gro -g job.log -e ener.edr -x traj.xtc 


For submitting jobs to the queue, run the following script preceded by qsub:

#!/bin/bash -x
#PBS -l nodes=2:ppn=4:xeon 
#PBS -l walltime=10:00:00
#PBS -l mem=1gb
#PBS -joe
#PBS -W x=\"NODESET:FIRSTOF:FEATURE:opteron:xeon\"
## Do not change this line

suff=_d_mpibull_gshmc

JOB="-s topol.tpr -o traj.trr -c confout.gro -g job.log -e ener.edr -x traj.xtc"

HOST=$(hostname)
echo Job runing on $HOST
cat $PBS_NODEFILE

cd $PBS_O_WORKDIR
scrt=/scratch/$USER/$PBS_JOBID
mkdir -p $scrt
cp -r $PBS_O_WORKDIR/* $scrt
cd $scrt

grompp$suff -f equil_nvt.mdp -c equil_nvt.gro -p neutral.top -po mdout.mdp -o topol.tpr -n index.ndx 

/usr/bin/time -p mpirun mdrun$suff -quiet  "$JOB" > $PBS_JOBID.out
echo "Gromacs Job Finished. Your results are on the $PBS_O_WORKDIR/$PBS_JOBID directory"

mv $scrt $PBS_O_WORKDIR

NOTES:
The lines starting by #PBS are commands for the queue manager. You can select the number of nodes, number of processors per node and processor architecture. You should also define the walltime as the maximum expected time for your process.

Parameters:

GSHMC uses some new parameters that you must add to your .mdp file:

; Generalized Shadow Hybrid Monte Carlo =
GSHMC                    = yes
parameter_phi            = 1.5
nr_mom_updates           = 5
variable_change          = no
nr_MD_steps              = 1000
hamiltonian_order        = 6
canonical_temperature    = 300
momentum_flip            = yes

Explanation of the above:
GSHMC: yes/no. If GSHMC=no then you run the standard version of gromacs without any GSHMC modifications.
parameter_phi: 0-1.57. This is the angle of the momentum update.
nr_mom_updates: >=1. This is the number of momentum update trials to be performed.
variable_change: yes/no. You can include a variable change in the momentum update to increase the acceptance rate.
nr_MD_steps: ~1000. This is the length of the MD trajectory between Monte Carlo tests. For testing purposes you can use shorter lengths (i.e. 100).
hamiltonian_order: options are 4 or 6. This is the order of approximation of the Shadow Hamiltonian.
canonical_temperature: temperature used for the generation of the random velocities in the momentum updates.
momentum_flip: yes/no. Choose if you want to perform a momentum flip after the rejection of an MD trajectory.

Other parameters in the .mdp file are also affected:
integrator=md-vv.  Always use the velocity Verlet algorithm for integrating Newton's equations of motion.
dt=0.001. This is the integrator timestep in picosecomds. It should be set to approximately half the value used on standard gromacs.
pcoupl=no, tcoupl=no. Pressure and temperature coupling should be turned off when using GSHMC
gen_vel=yes, gen_temp=300: gen_vel must be set to 'yes' in order to generate initial random velocities. Otherwise the Shadow Hamiltonians for the first MDMC test will be inaccurate. gen_temp should be the same as your canonical_temperature.
nstxout, nstvout, nstfout, nstxtcout, nstenergy: These parameters indicate respectively the frequency for writing coordinates, velocities, forces and xtc trajectories to the output files.  If they are 0, no output will be produced. If they are different than 0, GSHMC will respect their value but will wait to write output until after the next accepted MD trajectory.
nstcalcenergy: when using GSHMC, this parameter is automatically set to 1 during the 7 timesteps of the interpolation polynomial. This is necessary to ensure the precision of the Shadow Hamiltonians. 
lincs_iter=2, lincs_order=8: TESTING: apparently, when using constraints and domain decomposition the lincs algorithm requires a high order of precision and at least 2 iterations.



Affected source files:
This is a list of the modified source files from the standard gromacs-4.5.4:

src/kernel/md.c: The function do_md() contains the main MD loop over time in standard gromacs. The GSHMC algorithm is implemented within this loop.

The new parameters for the .mdp file are read and checked in the following files and functions:
include/types/inputrec.h
src/gmxlib/tpxio.c → tpx_version, do_inputrec()
src/gmxlib/txtdump.c → pr_intpurec()
src/kernel/readir.c → get_ir(), check_ir()
src/kernel/tpbcmp.c → cmp_inputrec()

src/mdlib/gshmc.c (and .h): These are the only newly created files. All functions necessary for the GSHMC algorithm are included here.




